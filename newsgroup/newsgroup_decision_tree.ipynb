{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12617,
     "status": "ok",
     "timestamp": 1584024456218,
     "user": {
      "displayName": "nadia blostein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmoWTnUuTZGAWRSOuX9K7QmAbtoR3oyqeijss=s64",
      "userId": "09797698255841311060"
     },
     "user_tz": 240
    },
    "id": "_5GuAEj85pdl",
    "outputId": "21ca5fc5-6996-4a90-9660-0a5fefee4bcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "########## DATA PREPARATION ##########\n",
    "######################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Script to download the 20 newsgroups text classification set\"\"\"\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "########## TRAIN DATA ##############\n",
    "# categories = ['alt.atheism' , 'soc.religion.christian' , 'comp.graphics' , 'sci.med'] # to match tutorial\n",
    "twenty_train = fetch_20newsgroups(subset = 'train', remove=(['headers', 'footers', 'quotes']))\n",
    "# twenty_train = fetch_20newsgroups(subset = 'train', categories=categories)\n",
    "\n",
    "########## TEST DATA ##############\n",
    "twenty_test = fetch_20newsgroups(subset = 'test', remove=(['headers', 'footers', 'quotes']))\n",
    "\n",
    "\"\"\"Define count vectorizer and tf-idf transformations\"\"\"\n",
    "\n",
    "###### Count Vectorizer #######\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "### Filter out these stopwords ####\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "#### Filter: Stopwords, token_pattern filters out the non-letter characters\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words = stopwords,  token_pattern = r'\\b[^\\d\\W_/]+\\b')\n",
    "\n",
    "########## TFIDF ############\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True,smooth_idf=True) # turned on idf and smooth idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vcOxc3kohiAi"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "########## Decision Tree: rough estimates ##########\n",
    "####################################################\n",
    "\n",
    "# packages:\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# function to roughly test parameters\n",
    "def rough_param_estimate(clf__min_samples_leaf, clf__min_samples_split, clf__max_depth):\n",
    "  decisiontree_clf = DecisionTreeClassifier()\n",
    "  decisiontree_params_gini = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': clf__min_samples_leaf, # 1 (default = 1)\n",
    "                        'clf__min_samples_split': clf__min_samples_split, # 3 when i input 2,3,4,5(default = 2)\n",
    "                      'clf__max_depth': clf__max_depth # depth, we toyed with 500 to 4000 (default = none)\n",
    "                        }\n",
    "  decision_tree_pipeline_gini = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "  \n",
    "  clf_gini = RandomizedSearchCV(decision_tree_pipeline_gini, decisiontree_params_gini, cv=5, n_jobs=-1)\n",
    "\n",
    "  search_gini = clf_gini.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "  print(\"Best estimator with Gini criterion (randomized search): \" + str(search_gini.best_params_))\n",
    "  print(\"Best score with Gini criterion (randomized search):\" + str(search_gini.best_score_))\n",
    "  print(\"Mean Fit Time with Gini criterion (randomized search):\" + str(search_gini.cv_results_.get('mean_fit_time')))\n",
    "\n",
    "  decisiontree_params_entropy = {'clf__criterion': ['entropy'], \n",
    "                        'clf__min_samples_leaf': clf__min_samples_leaf, # 1 (default = 1)\n",
    "                        'clf__min_samples_split': clf__min_samples_split, # 3 when i input 2,3,4,5(default = 2)\n",
    "                        'clf__max_depth': clf__max_depth #depth, we toyed with 500 to 4000 (default = none)\n",
    "                        }\n",
    "  decision_tree_pipeline_entropy = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "  clf_entropy = RandomizedSearchCV(decision_tree_pipeline_entropy, decisiontree_params_entropy, cv=5, n_jobs=4)\n",
    "  search_entropy = clf_entropy.fit(twenty_train.data, twenty_train.target)\n",
    "  print(\"Best estimator with Entropy criterion (randomized search): \" + str(search_entropy.best_params_))\n",
    "  print(\"Best score with Entropy criterion (randomized search):\" + str(search_entropy.best_score_))\n",
    "  print(\"Mean Fit Time with Entropy criterion (randomized search):\" + str(search_entropy.cv_results_.get('mean_fit_time')))\n",
    "clf__min_samples_leaf = [1]\n",
    "clf__min_samples_split = [2,3,4]\n",
    "clf__max_depth = [250,500,750]\n",
    "rough_param_estimate(clf__min_samples_leaf, clf__min_samples_split, clf__max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1304702,
     "status": "ok",
     "timestamp": 1583872389135,
     "user": {
      "displayName": "nadia blostein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmoWTnUuTZGAWRSOuX9K7QmAbtoR3oyqeijss=s64",
      "userId": "09797698255841311060"
     },
     "user_tz": 240
    },
    "id": "R2lfrl0z507L",
    "outputId": "7c17b900-4ebe-464a-c33f-771c9b695b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator with Gini criterion (randomized search): {'clf__min_samples_split': 7, 'clf__min_samples_leaf': 1, 'clf__criterion': 'gini'}\n",
      "Best score with Gini criterion (randomized search):0.4658834524408145\n",
      "Mean Fit Time with Gini criterion (randomized search):[40.56883984 37.67145109 34.87990828 38.43001657 35.11679025 34.54104257\n",
      " 37.10123801 36.06419778 35.72085252 29.14020457]\n",
      "Best estimator with Entropy criterion (randomized search): {'clf__min_samples_split': 6, 'clf__min_samples_leaf': 1, 'clf__criterion': 'entropy'}\n",
      "Best score with Entropy criterion (randomized search):0.35734592508633684\n",
      "Mean Fit Time with Entropy criterion (randomized search):[66.62211881 63.0900722  69.01786757 58.4111279  56.44176087 64.15077138\n",
      " 60.74244342 57.4838346  61.34027867 47.6233387 ]\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "########## Decision Tree: model comparison ##########\n",
    "#####################################################\n",
    "\n",
    "# packages:\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "decisiontree_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Model 1: Gini, min samples split = 2\n",
    "decisiontree_params_gini_1 = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], \n",
    "                            'clf__max_depth': [250, 500, 750, 1000]}\n",
    "decision_tree_pipeline_gini_1 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_gini_1 = RandomizedSearchCV(decision_tree_pipeline_gini_1, decisiontree_params_gini_1, cv=5, n_jobs=-1)\n",
    "search_gini_1 = clf_gini_1.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"Best estimator with Gini criterion, min sample split = 2 (randomized search): \" + str(search_gini_1.best_params_))\n",
    "print(\"Best score with Gini criterion, min sample split = 2 (randomized search):\" + str(search_gini_1.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Gini, min sample split = 2) with best params: \" + str(search_gini_1.best_estimator_.score(twenty_test.data, twenty_test.target)))\n",
    "\n",
    "# Model 2: Entropy, min samples split = 2\n",
    "decisiontree_params_entropy_1 = {'clf__criterion': ['entropy'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], \n",
    "                            'clf__max_depth': [250, 500, 750, 1000]}\n",
    "decision_tree_pipeline_entropy_1 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_entropy_1 = RandomizedSearchCV(decision_tree_pipeline_entropy_1, decisiontree_params_entropy_1, cv=5, n_jobs=-1)\n",
    "search_entropy_1 = clf_entropy_1.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"Best estimator with Entropy criterion, min sample split = 2 (randomized search): \" + str(search_entropy_1.best_params_))\n",
    "print(\"Best score with Entropy criterion, min sample split = 2 (randomized search):\" + str(search_entropy_1.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Entropy, min sample split = 2) with best params: \" + str(search_entropy_1.best_estimator_.score(twenty_test.data, twenty_test.target)))\n",
    "\n",
    "# Model 3: Gini, min samples split = 3\n",
    "decisiontree_params_gini_2 = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [3], \n",
    "                            'clf__max_depth': [250, 500, 750, 1000]}\n",
    "decision_tree_pipeline_gini_2 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_gini_2 = RandomizedSearchCV(decision_tree_pipeline_gini_2, decisiontree_params_gini_2, cv=5, n_jobs=-1)\n",
    "search_gini_2 = clf_gini_2.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"Best estimator with Gini criterion, min sample split = 3 (randomized search): \" + str(search_gini_2.best_params_))\n",
    "print(\"Best score with Gini criterion, min sample split = 3 (randomized search):\" + str(search_gini_2.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Gini, min sample split = 3) with best params: \" + str(search_gini_2.best_estimator_.score(twenty_test.data, twenty_test.target)))\n",
    "\n",
    "# Model 4: Entropy, min samples split = 3\n",
    "decisiontree_params_entropy_2 = {'clf__criterion': ['entropy'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], \n",
    "                            'clf__max_depth': [250, 500, 750, 1000]}\n",
    "decision_tree_pipeline_entropy_2 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_entropy_2 = RandomizedSearchCV(decision_tree_pipeline_entropy_2, decisiontree_params_entropy_2, cv=5, n_jobs=-1)\n",
    "search_entropy_2 = clf_entropy_2.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"Best estimator with Entropy criterion, min sample split = 3 (randomized search): \" + str(search_entropy_2.best_params_))\n",
    "print(\"Best score with Entropy criterion, min sample split = 3 (randomized search):\" + str(search_entropy_2.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Entropy, min sample split = 3) with best params: \" + str(search_entropy_2.best_estimator_.score(twenty_test.data, twenty_test.target)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vlWtwVVl_VRt"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "########## Decision Tree: model comparison graph ##########\n",
    "###########################################################\n",
    "\n",
    "if not os.path.exists('decision_tree'):\n",
    "  os.makedirs('decision_tree')\n",
    "\n",
    "plt.plot(list(search_gini_1.cv_results_.get('param_clf__max_depth')), search_gini_1.cv_results_.get('mean_test_score'), label = 'Gini, min sample split = 2')\n",
    "plt.plot(list(search_entropy_1.cv_results_.get('param_clf__max_depth')), search_entropy_1.cv_results_.get('mean_test_score'), label = 'Entropy, min sample split = 2')\n",
    "plt.plot(list(search_gini_2.cv_results_.get('param_clf__max_depth')), search_gini_2.cv_results_.get('mean_test_score'), label = 'Gini, min sample split = 3')\n",
    "plt.plot(list(search_entropy_2.cv_results_.get('param_clf__max_depth')), search_entropy_2.cv_results_.get('mean_test_score'), label = 'Entropy, min sample split = 3')\n",
    "\n",
    "plt.xlabel(\"Max Tree Depth\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.title(\"Decision Tree: Accuracy over Max Tree Depth (randomized search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"decision_tree/decision_tree_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(search_gini_1.cv_results_.get('param_clf__max_depth')), search_gini_1.cv_results_.get('mean_fit_time'), label = 'Gini, min sample split = 2')\n",
    "plt.plot(list(search_entropy_1.cv_results_.get('param_clf__max_depth')), search_entropy_1.cv_results_.get('mean_fit_time'), label = 'Entropy, min sample split = 2')\n",
    "plt.plot(list(search_gini_2.cv_results_.get('param_clf__max_depth')), search_gini_2.cv_results_.get('mean_fit_time'), label = 'Gini, min sample split = 3')\n",
    "plt.plot(list(search_entropy_2.cv_results_.get('param_clf__max_depth')), search_entropy_2.cv_results_.get('mean_fit_time'), label = 'Entropy, min sample split = 3')\n",
    "\n",
    "plt.xlabel(\"Max Tree Depth\")\n",
    "plt.ylabel(\"Mean Fit Time (Seconds)\")\n",
    "plt.title(\"Decision Tree: Mean Fit Time over Max Tree Depth (randomized search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"decision_tree/decision_tree_time.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOfmMDROWPUugslOX51/xXs",
   "collapsed_sections": [],
   "name": "newsgroup_decision_tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
