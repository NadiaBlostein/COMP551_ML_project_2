{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################                    \n",
    "############################ DATA PREPARATION ############################\n",
    "##########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"Script to process IMDB dataset\"\"\"\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos = 'aclImdb/train/pos/'\n",
    "filelist_pos = os.listdir(path_pos) ####the fileist is not ordered by name of file \n",
    "data_pos= []\n",
    "j=0\n",
    "id_rating_pos = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos:\n",
    "    f = open(path_pos+file, 'r', encoding='utf8')\n",
    "    data_pos.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "    \n",
    "#### Get the y_train as the ratings\n",
    "rating_pos = []\n",
    "\n",
    "for i in id_rating_pos:\n",
    "    #rating_pos.append(i[1])\n",
    "    rating_pos.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "\n",
    "## directory: aclImdb/train/pos/FILES & aclImdb/train/neg/FILES ##\n",
    "path_neg = 'aclImdb/train/neg/'\n",
    "filelist_neg = os.listdir(path_neg) ####the fileist is not ordered by name of file \n",
    "data_neg= []\n",
    "i=0\n",
    "id_rating_neg = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg:\n",
    "    f = open(path_neg+file, 'r', encoding='utf8')\n",
    "    data_neg.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "\n",
    "rating_neg = []\n",
    "\n",
    "for i in id_rating_neg:\n",
    "    #rating_neg.append(i[1])\n",
    "    rating_neg.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "##### APPEND BOTH POS & NEG TRAINING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "\n",
    "X_train_IMDb = data_pos+data_neg # as a list\n",
    "X_train_IMDb_np = np.array(X_train_IMDb) # NOT NEEDED\n",
    "y_train_IMDb = np.array(rating_pos+rating_neg)# as a numpy array\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos_test = 'aclImdb/test/pos/'\n",
    "filelist_pos_test = os.listdir(path_pos_test) ####the fileist is not ordered by name of file \n",
    "data_pos_test= []\n",
    "j=0\n",
    "id_rating_pos_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos_test:\n",
    "    f = open(path_pos_test+file, 'r', encoding='utf8')\n",
    "    data_pos_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos_test.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "\n",
    "#### Get the y_train as the ratings\n",
    "rating_pos_test = []\n",
    "\n",
    "for i in id_rating_pos_test:\n",
    "    #rating_pos_test.append(i[1])\n",
    "    rating_pos_test.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "\n",
    "path_neg_test = 'aclImdb/test/neg/'\n",
    "filelist_neg_test = os.listdir(path_neg_test) ####the fileist is not ordered by name of file \n",
    "data_neg_test= []\n",
    "i=0\n",
    "id_rating_neg_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg_test:\n",
    "    f = open(path_neg_test+file, 'r', encoding='utf8')\n",
    "    data_neg_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg_test.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "rating_neg_test = []\n",
    "\n",
    "for i in id_rating_neg_test:\n",
    "    #rating_neg_test.append(i[1])\n",
    "    rating_neg_test.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "##### APPEND BOTH POS & NEG TESTING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "\n",
    "X_test_IMDb = data_pos_test+data_neg_test # as a list\n",
    "X_test_IMDb_np = np.array(X_test_IMDb) # NOT NEEDED\n",
    "y_test_IMDb = np.array(rating_pos_test+rating_neg_test)# as a numpy array\n",
    "\n",
    "\"\"\"Define count vectorizer and tf-idf transformations\"\"\"\n",
    "\n",
    "###### Count Vectorizer #######\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "### Filter out these stopwords ####\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "#### Filter: Stopwords, token_pattern filters out the non-letter characters\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words = stopwords,  token_pattern = r'\\b[^\\d\\W_/]+\\b')\n",
    "\n",
    "########## TFIDF ############\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True,smooth_idf=True) # turned on idf and smooth idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator with Gini criterion, min sample split = 2 (randomized search): {'clf__criterion': 'gini', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 600}\n",
      "Best score with Gini criterion, min sample split = 2 (randomized search):0.86184\n",
      "Test accuracy of Random Forest (Gini, min sample split = 2) with best params: 0.86208\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rrandforest_params_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f0a87267c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mrandforest_params_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'clf__criterion'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf__min_samples_leaf'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf__min_samples_split'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf__n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mrandforest_pipeline_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandforest_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mrandforest_CV_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandforest_pipeline_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrrandforest_params_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 5-fold cross-val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0msearch_randforest_CV_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandforest_CV_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_IMDb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_IMDb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best estimator with Gini criterion, min sample split = 3 (randomized search): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_randforest_CV_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rrandforest_params_2' is not defined"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "### Random Forest: best n estimators ###\n",
    "########################################\n",
    "\n",
    "# packages\n",
    "import os  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randforest_clf = RandomForestClassifier()\n",
    "\n",
    "# Model 1: Gini Criterion, Min Samples Split = 2\n",
    "randforest_params_1 = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], 'clf__n_estimators': [100,200,300,400,500, 600]}\n",
    "randforest_pipeline_1 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', randforest_clf)])\n",
    "randforest_CV_1 = GridSearchCV(randforest_pipeline_1, param_grid=randforest_params_1, cv=5, n_jobs=-1) # 5-fold cross-val - no advantage to randomized search here\n",
    "search_randforest_CV_1 = randforest_CV_1.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Gini criterion, min sample split = 2 (grid search): \" + str(search_randforest_CV_1.best_params_))\n",
    "print(\"Best score with Gini criterion, min sample split = 2 (grid search):\" + str(search_randforest_CV_1.best_score_))\n",
    "print(\"Test accuracy of Random Forest (Gini, min sample split = 2) with best params: \" + str(search_randforest_CV_1.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "# Model 2: Gini Criterion, Min Samples Split = 3\n",
    "randforest_params_2 = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [3], 'clf__n_estimators': [100,200,300,400,500, 600]}\n",
    "randforest_pipeline_2 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', randforest_clf)])\n",
    "randforest_CV_2 = GridSearchCV(randforest_pipeline_2, param_grid=rrandforest_params_2, cv=5, n_jobs=-1) # 5-fold cross-val\n",
    "search_randforest_CV_2 = randforest_CV_2.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Gini criterion, min sample split = 3 (grid search): \" + str(search_randforest_CV_2.best_params_))\n",
    "print(\"Best score with Gini criterion, min sample split = 3 (grid search):\" + str(search_randforest_CV_2.best_score_))\n",
    "print(\"Test accuracy of Random Forest (Gini, min sample split = 3) with best params: \" + str(search_randforest_CV_2.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "# Model 3: Entropy Criterion, Min Samples Split = 2\n",
    "randforest_params_3 = {'clf__criterion': ['entropy'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], 'clf__n_estimators': [100,200,300,400,500, 600]}\n",
    "randforest_pipeline_3 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', randforest_clf)])\n",
    "randforest_CV_3 = GridSearchCV(randforest_pipeline_3, param_grid=rrandforest_params_3, cv=5, n_jobs=-1) # 5-fold cross-val\n",
    "search_randforest_CV_3 = randforest_CV_3.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with entropy criterion, min sample split = 2 (grid search): \" + str(search_randforest_CV_3.best_params_))\n",
    "print(\"Best score with entropy criterion, min sample split = 2 (grid search):\" + str(search_randforest_CV_3.best_score_))\n",
    "print(\"Test accuracy of Random Forest (entropy, min sample split = 2) with best params: \" + str(search_randforest_CV_3.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "# Model 4: Entropy Criterion, Min Samples Split = 3\n",
    "randforest_params_4 = {'clf__criterion': ['entropy'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [3], 'clf__n_estimators': [100,200,300,400,500, 600]}\n",
    "randforest_pipeline_4 = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', randforest_clf)])\n",
    "randforest_CV_4 = GridSearchCV(randforest_pipeline_4, param_grid=rrandforest_params_4, cv=5, n_jobs=-1) # 5-fold cross-val\n",
    "search_randforest_CV_4 = randforest_CV_4.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Entropy criterion, min sample split = 3 (grid search): \" + str(search_randforest_CV_4.best_params_))\n",
    "print(\"Best score with Entropy criterion, min sample split = 3 (grid search):\" + str(search_randforest_CV_4.best_score_))\n",
    "print(\"Test accuracy of Random Forest (Entropy, min sample split = 3) with best params: \" + str(search_randforest_CV_4.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "# graph\n",
    "\n",
    "if not os.path.exists('imbd/random_forest'):\n",
    "  os.makedirs('imbd/random_forest')\n",
    "\n",
    "plt.plot(list(search_randforest_CV_1.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_1.cv_results_.get('mean_test_score'), label = 'Gini, min sample split = 2')\n",
    "plt.plot(list(search_randforest_CV_2.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_2.cv_results_.get('mean_test_score'), label = 'Gini, min sample split = 3')\n",
    "plt.plot(list(search_randforest_CV_3.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_3.cv_results_.get('mean_test_score'), label = 'Entropy, min sample split = 2')\n",
    "plt.plot(list(search_randforest_CV_4.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_4.cv_results_.get('mean_test_score'), label = 'Entropy, min sample split = 3')\n",
    "\n",
    "plt.xlabel(\"n estimators\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.title(\"Random Forest: Accuracy over # of estimators (grid search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"imbd/random_forest/random_forest_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(search_randforest_CV_1.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_1.cv_results_.get('mean_fit_time'), label = 'Gini, min sample split = 2')\n",
    "plt.plot(list(search_randforest_CV_2.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_2.cv_results_.get('mean_fit_time'), label = 'Gini, min sample split = 3')\n",
    "plt.plot(list(search_randforest_CV_3.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_3.cv_results_.get('mean_fit_time'), label = 'Entropy, min sample split = 2')\n",
    "plt.plot(list(search_randforest_CV_4.cv_results_.get('param_clf__n_estimators')), search_randforest_CV_4.cv_results_.get('mean_fit_time'), label = 'Entropy, min sample split = 3')\n",
    "\n",
    "plt.xlabel(\"n estimators\")\n",
    "plt.ylabel(\"Mean Fit Time (Seconds)\")\n",
    "plt.title(\"Random Forest: Mean Fit Time over # of estimators (grid search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"imbd/random_forest/random_forest_time.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
