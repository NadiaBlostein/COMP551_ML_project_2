{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################                    \n",
    "############################ DATA PREPARATION ############################\n",
    "##########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"Script to process IMDB dataset\"\"\"\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos = 'aclImdb/train/pos/'\n",
    "filelist_pos = os.listdir(path_pos) ####the fileist is not ordered by name of file \n",
    "data_pos= []\n",
    "j=0\n",
    "id_rating_pos = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos:\n",
    "    f = open(path_pos+file, 'r', encoding='utf8')\n",
    "    data_pos.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "    \n",
    "#### Get the y_train as the ratings\n",
    "rating_pos = []\n",
    "\n",
    "for i in id_rating_pos:\n",
    "    #rating_pos.append(i[1])\n",
    "    rating_pos.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "\n",
    "## directory: aclImdb/train/pos/FILES & aclImdb/train/neg/FILES ##\n",
    "path_neg = 'aclImdb/train/neg/'\n",
    "filelist_neg = os.listdir(path_neg) ####the fileist is not ordered by name of file \n",
    "data_neg= []\n",
    "i=0\n",
    "id_rating_neg = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg:\n",
    "    f = open(path_neg+file, 'r', encoding='utf8')\n",
    "    data_neg.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "\n",
    "rating_neg = []\n",
    "\n",
    "for i in id_rating_neg:\n",
    "    #rating_neg.append(i[1])\n",
    "    rating_neg.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "##### APPEND BOTH POS & NEG TRAINING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "\n",
    "X_train_IMDb = data_pos+data_neg # as a list\n",
    "X_train_IMDb_np = np.array(X_train_IMDb) # NOT NEEDED\n",
    "y_train_IMDb = np.array(rating_pos+rating_neg)# as a numpy array\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos_test = 'aclImdb/test/pos/'\n",
    "filelist_pos_test = os.listdir(path_pos_test) ####the fileist is not ordered by name of file \n",
    "data_pos_test= []\n",
    "j=0\n",
    "id_rating_pos_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos_test:\n",
    "    f = open(path_pos_test+file, 'r', encoding='utf8')\n",
    "    data_pos_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos_test.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "\n",
    "#### Get the y_train as the ratings\n",
    "rating_pos_test = []\n",
    "\n",
    "for i in id_rating_pos_test:\n",
    "    #rating_pos_test.append(i[1])\n",
    "    rating_pos_test.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "\n",
    "path_neg_test = 'aclImdb/test/neg/'\n",
    "filelist_neg_test = os.listdir(path_neg_test) ####the fileist is not ordered by name of file \n",
    "data_neg_test= []\n",
    "i=0\n",
    "id_rating_neg_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg_test:\n",
    "    f = open(path_neg_test+file, 'r', encoding='utf8')\n",
    "    data_neg_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg_test.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "rating_neg_test = []\n",
    "\n",
    "for i in id_rating_neg_test:\n",
    "    #rating_neg_test.append(i[1])\n",
    "    rating_neg_test.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "##### APPEND BOTH POS & NEG TESTING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "\n",
    "X_test_IMDb = data_pos_test+data_neg_test # as a list\n",
    "X_test_IMDb_np = np.array(X_test_IMDb) # NOT NEEDED\n",
    "y_test_IMDb = np.array(rating_pos_test+rating_neg_test)# as a numpy array\n",
    "\n",
    "\"\"\"Define count vectorizer and tf-idf transformations\"\"\"\n",
    "\n",
    "###### Count Vectorizer #######\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "### Filter out these stopwords ####\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "#### Filter: Stopwords, token_pattern filters out the non-letter characters\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words = stopwords,  token_pattern = r'\\b[^\\d\\W_/]+\\b')\n",
    "\n",
    "########## TFIDF ############\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True,smooth_idf=True) # turned on idf and smooth idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'\\nprint(\"L2 penalty, hinge loss, best C: \"+ str(SVM_CV_1.best_params_[\\'clf__C\\']))\\nprint(\"L2 penalty, hinge loss, best score: \"+ str(SVM_CV_1.best_score_))\\nprint(\"Test accuracy of SVM (L2, hinge) with best params: \" + str(SVM_CV_1.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\\n\\n# Plot for SVM Model 1\\nplt.plot(list(SVM_CV_1.cv_results_.get(\\'param_clf__C\\')), SVM_CV_1.cv_results_.get(\\'mean_test_score\\'), label = \\'L2 penalty, hinge loss\\')\\nplt.plot(list(SVM_CV_2.cv_results_.get(\\'param_clf__C\\')), SVM_CV_2.cv_results_.get(\\'mean_test_score\\'),label = \\'L2 penalty, squared hinge loss\\')\\nplt.plot(list(SVM_CV_2.cv_results_.get(\\'param_clf__C\\')), SVM_CV_3.cv_results_.get(\\'mean_test_score\\'),label = \\'L1 penalty, squared hinge loss\\')\\n\\nplt.xlabel(\"C\")\\nplt.ylabel(\"Mean accuracy\")\\nplt.title(\"SVM: Accuracy Over C (Randomized Search)\")\\nplt.legend()\\nplt.savefig(\"SVM/imbd_accuracy_curve.png\")\\nplt.show()\\n\\nplt.plot(list(SVM_CV_1.cv_results_.get(\\'param_clf__C\\')), SVM_CV_1.cv_results_.get(\\'mean_fit_time\\'), label = \\'L2 penalty, hinge loss\\')\\nplt.plot(list(SVM_CV_2.cv_results_.get(\\'param_clf__C\\')), SVM_CV_2.cv_results_.get(\\'mean_fit_time\\'),label = \\'L2 penalty, squared hinge loss\\')\\nplt.plot(list(SVM_CV_2.cv_results_.get(\\'param_clf__C\\')), SVM_CV_3.cv_results_.get(\\'mean_fit_time\\'),label = \\'L1 penalty, squared hinge loss\\')\\nplt.xlabel(\"C\")\\nplt.ylabel(\"Mean fit time (seconds)\")\\nplt.title(\"SVM: Mean Fit Time Over C (Randomized Search)\")\\nplt.legend()\\nplt.savefig(\"SVM/imbd_time_curve.png\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "### SVM: Varying C (L2 penalty, Hinge Loss) ###\n",
    "###############################################\n",
    "\n",
    "# packages\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "\n",
    "clf_C = [1,2,3,4,5]\n",
    "\n",
    "if not os.path.exists('SVM'):\n",
    "    os.makedirs('SVM')\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "SVM_pipeline = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', svm_clf)])\n",
    "\n",
    "svm_params_1 = {'clf__penalty': ['l2'], 'clf__loss': ['hinge'], 'clf__max_iter': [10000], 'clf__C': clf_C} # smaller C <=> stronger regularization\n",
    "SVM_CV_1 = GridSearchCV(SVM_pipeline, param_grid=svm_params_1, cv=5, n_jobs=4) # 5-fold cross-val\n",
    "SVM_CV_1.fit(X_train_IMDb, y_train_IMDb)\n",
    "\n",
    "print(\"L2 penalty, hinge loss, best C: \"+ str(SVM_CV_1.best_params_['clf__C']))\n",
    "print(\"L2 penalty, hinge loss, best score: \"+ str(SVM_CV_1.best_score_))\n",
    "print(\"Test accuracy of SVM (L2, hinge) with best params: \" + str(SVM_CV_1.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.plot(list(SVM_CV_1.cv_results_.get('param_clf__C')), SVM_CV_1.cv_results_.get('mean_test_score'))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.title(\"SVM (L2 penalty, hinge loss): Accuracy Over C (Grid Search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"SVM/imbd_SVM_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# Time Plot\n",
    "plt.plot(list(SVM_CV_1.cv_results_.get('param_clf__C')), SVM_CV_1.cv_results_.get('mean_fit_time'), label = 'L2 penalty, hinge loss')\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean Fit Time (seconds)\")\n",
    "plt.title(\"SVM (L2 penalty, hinge loss): Mean Fit Time (seconds) Over C (Grid Search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"SVM/imbd_SVM_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
