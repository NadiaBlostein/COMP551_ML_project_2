{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################                    \n",
    "############################ DATA PREPARATION ############################\n",
    "##########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"Script to process IMDB dataset\"\"\"\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos = 'aclImdb/train/pos/'\n",
    "filelist_pos = os.listdir(path_pos) ####the fileist is not ordered by name of file \n",
    "data_pos= []\n",
    "j=0\n",
    "id_rating_pos = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos:\n",
    "    f = open(path_pos+file, 'r', encoding='utf8')\n",
    "    data_pos.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "    \n",
    "#### Get the y_train as the ratings\n",
    "rating_pos = []\n",
    "\n",
    "for i in id_rating_pos:\n",
    "    #rating_pos.append(i[1])\n",
    "    rating_pos.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TRAIN DATA #####\n",
    "                        ######################################\n",
    "\n",
    "## directory: aclImdb/train/pos/FILES & aclImdb/train/neg/FILES ##\n",
    "path_neg = 'aclImdb/train/neg/'\n",
    "filelist_neg = os.listdir(path_neg) ####the fileist is not ordered by name of file \n",
    "data_neg= []\n",
    "i=0\n",
    "id_rating_neg = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg:\n",
    "    f = open(path_neg+file, 'r', encoding='utf8')\n",
    "    data_neg.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "\n",
    "rating_neg = []\n",
    "\n",
    "for i in id_rating_neg:\n",
    "    #rating_neg.append(i[1])\n",
    "    rating_neg.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "##### APPEND BOTH POS & NEG TRAINING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ###\n",
    "\n",
    "X_train_IMDb = data_pos+data_neg # as a list\n",
    "X_train_IMDb_np = np.array(X_train_IMDb) # NOT NEEDED\n",
    "y_train_IMDb = np.array(rating_pos+rating_neg)# as a numpy array\n",
    "    \n",
    "                        ######################################                    \n",
    "                        #### POSITIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "            \n",
    "\n",
    "\n",
    "path_pos_test = 'aclImdb/test/pos/'\n",
    "filelist_pos_test = os.listdir(path_pos_test) ####the fileist is not ordered by name of file \n",
    "data_pos_test= []\n",
    "j=0\n",
    "id_rating_pos_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_pos_test:\n",
    "    f = open(path_pos_test+file, 'r', encoding='utf8')\n",
    "    data_pos_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_pos_test.append(name.split(\"_\"))\n",
    "    \n",
    "    j=j+1\n",
    "    f.close()\n",
    "\n",
    "#### Get the y_train as the ratings\n",
    "rating_pos_test = []\n",
    "\n",
    "for i in id_rating_pos_test:\n",
    "    #rating_pos_test.append(i[1])\n",
    "    rating_pos_test.append('1') # as per myCourses announcement, should do binary classification - all pos reviews labeled '1'\n",
    "\n",
    "                        ######################################                    \n",
    "                        #### NEGATIVE REVIEWS TEST DATA #####\n",
    "                        ######################################\n",
    "\n",
    "path_neg_test = 'aclImdb/test/neg/'\n",
    "filelist_neg_test = os.listdir(path_neg_test) ####the fileist is not ordered by name of file \n",
    "data_neg_test= []\n",
    "i=0\n",
    "id_rating_neg_test = []\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#iterate through files in directory\n",
    "for file in filelist_neg_test:\n",
    "    f = open(path_neg_test+file, 'r', encoding='utf8')\n",
    "    data_neg_test.append((f.read()))\n",
    "    \n",
    "    name = os.path.splitext(file)[0]\n",
    "    id_rating_neg_test.append(name.split(\"_\"))\n",
    "    \n",
    "    i=i+1\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "rating_neg_test = []\n",
    "\n",
    "for i in id_rating_neg_test:\n",
    "    #rating_neg_test.append(i[1])\n",
    "    rating_neg_test.append('0') # as per myCourses announcement, should do binary classification - all neg reviews labeled '0'\n",
    "    \n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "##### APPEND BOTH POS & NEG TESTING DATASETS #####\n",
    "##### ##### ##### ##### ##### ##### ##### ##### ##\n",
    "\n",
    "X_test_IMDb = data_pos_test+data_neg_test # as a list\n",
    "X_test_IMDb_np = np.array(X_test_IMDb) # NOT NEEDED\n",
    "y_test_IMDb = np.array(rating_pos_test+rating_neg_test)# as a numpy array\n",
    "\n",
    "\"\"\"Define count vectorizer and tf-idf transformations\"\"\"\n",
    "\n",
    "###### Count Vectorizer #######\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "### Filter out these stopwords ####\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "#### Filter: Stopwords, token_pattern filters out the non-letter characters\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words = stopwords,  token_pattern = r'\\b[^\\d\\W_/]+\\b')\n",
    "\n",
    "########## TFIDF ############\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True,smooth_idf=True) # turned on idf and smooth idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-23b3777da744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mclf_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree_pipeline_gini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecisiontree_params_gini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msearch_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_gini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_IMDb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_IMDb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best estimator with Gini criterion (randomized search): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_gini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "########## Decision Tree: rough estimates ##########\n",
    "####################################################\n",
    "\n",
    "# packages:\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# function to roughly test parameters\n",
    "clf__min_samples_leaf = [1]\n",
    "clf__min_samples_split = [2,3,4]\n",
    "clf__max_depth = [250,500,750]\n",
    "\n",
    "decisiontree_clf = DecisionTreeClassifier()\n",
    "decisiontree_params_gini = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': clf__min_samples_leaf, # 1 (default = 1)\n",
    "                    'clf__min_samples_split': clf__min_samples_split, # 3 when i input 2,3,4,5(default = 2)\n",
    "                  'clf__max_depth': clf__max_depth # depth, we toyed with 500 to 4000 (default = none)\n",
    "                    }\n",
    "decision_tree_pipeline_gini = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "\n",
    "clf_gini = GridSearchCV(decision_tree_pipeline_gini, param_grid=decisiontree_params_gini, cv=5, n_jobs=-1)\n",
    "\n",
    "search_gini = clf_gini.fit(X_train_IMDb, y_train_IMDb)\n",
    "\n",
    "print(\"Best estimator with Gini criterion (randomized search): \" + str(search_gini.best_params_))\n",
    "print(\"Best score with Gini criterion (randomized search):\" + str(search_gini.best_score_))\n",
    "print(\"Mean Fit Time with Gini criterion (randomized search):\" + str(search_gini.cv_results_.get('mean_fit_time')))\n",
    "\n",
    "# OUTPUT:\n",
    "# {'clf__criterion': 'gini', 'clf__max_depth': 750, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 3}\n",
    "\n",
    "decisiontree_params_entropy = {'clf__criterion': ['entropy'], \n",
    "                    'clf__min_samples_leaf': clf__min_samples_leaf, # 1 (default = 1)\n",
    "                    'clf__min_samples_split': clf__min_samples_split, # 3 when i input 2,3,4,5(default = 2)\n",
    "                    'clf__max_depth': clf__max_depth #depth, we toyed with 500 to 4000 (default = none)\n",
    "                    }\n",
    "decision_tree_pipeline_entropy = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_entropy = GridSearchCV(decision_tree_pipeline_entropy, param_grid=decisiontree_params_entropy, cv=5, n_jobs=4)\n",
    "search_entropy = clf_entropy.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Entropy criterion (grid search): \" + str(search_entropy.best_params_))\n",
    "print(\"Best score with Entropy criterion (grid search):\" + str(search_entropy.best_score_))\n",
    "print(\"Mean Fit Time with Entropy criterion (grid search):\" + str(search_entropy.cv_results_.get('mean_fit_time')))\n",
    "\n",
    "decisiontree_params_entropy = {'clf__criterion': ['entropy'], \n",
    "                    'clf__min_samples_leaf': clf__min_samples_leaf, 'clf__min_samples_split': clf__min_samples_split, \n",
    "                    'clf__max_depth': clf__max_depth }\n",
    "decision_tree_pipeline_entropy = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_entropy = GridSearchCV(decision_tree_pipeline_entropy, param_grid=decisiontree_params_entropy, cv=5, n_jobs=4)\n",
    "search_entropy = clf_entropy.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Entropy criterion (grid search): \" + str(search_entropy.best_params_))\n",
    "print(\"Best score with Entropy criterion (grid search):\" + str(search_entropy.best_score_))\n",
    "print(\"Mean Fit Time with Entropy criterion (grid search):\" + str(search_entropy.cv_results_.get('mean_fit_time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator with Gini criterion (grid search): {'clf__criterion': 'gini', 'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 3}\n",
      "Best score with Gini criterion (grid search):0.71648\n",
      "Test accuracy of Decision Tree (Gini) with best params: 0.72248\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decisiontree_params_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-58e9eafaa2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                             'clf__max_depth': depth}\n\u001b[1;32m     28\u001b[0m \u001b[0mdecision_tree_pipeline_entropy_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecisiontree_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mclf_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree_pipeline_entropy_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecisiontree_params_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0msearch_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_IMDb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_IMDb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best estimator with Entropy criterion, min sample split = 2 (randomized search): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decisiontree_params_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "########## Decision Tree: model comparison ##########\n",
    "#####################################################\n",
    "\n",
    "# packages:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "decisiontree_clf = DecisionTreeClassifier()\n",
    "\n",
    "depth = [100,200,300,400,500,600,700,800,900,1000]\n",
    "\n",
    "# Model 1: Gini (min sample split = 3 from rough estimates run in previous cell)\n",
    "decisiontree_params_gini = {'clf__criterion': ['gini'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [3], \n",
    "                            'clf__max_depth': depth}\n",
    "decision_tree_pipeline_gini = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_gini = GridSearchCV(decision_tree_pipeline_gini, param_grid=decisiontree_params_gini, cv=5, n_jobs=-1)\n",
    "search_gini = clf_gini.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Gini criterion (grid search): \" + str(search_gini.best_params_))\n",
    "print(\"Best score with Gini criterion (grid search):\" + str(search_gini.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Gini) with best params: \" + str(search_gini.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "\n",
    "# Model 2: Entropy (min sample split = 2 from rough estimates run in previous cell)\n",
    "decisiontree_params_entropy = {'clf__criterion': ['entropy'], 'clf__min_samples_leaf': [1], 'clf__min_samples_split': [2], \n",
    "                            'clf__max_depth': depth}\n",
    "decision_tree_pipeline_entropy = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', decisiontree_clf)])\n",
    "clf_entropy = GridSearchCV(decision_tree_pipeline_entropy, param_grid=decisiontree_params_entropy, cv=5, n_jobs=-1)\n",
    "search_entropy = clf_entropy.fit(X_train_IMDb, y_train_IMDb)\n",
    "print(\"Best estimator with Entropy criterion, min sample split = 2 (randomized search): \" + str(search_entropy.best_params_))\n",
    "print(\"Best score with Entropy criterion, min sample split = 2 (randomized search):\" + str(search_entropy.best_score_))\n",
    "print(\"Test accuracy of Decision Tree (Entropy, min sample split = 2) with best params: \" + str(search_entropy.best_estimator_.score(X_test_IMDb, y_test_IMDb)))\n",
    "\n",
    "if not os.path.exists('decision_tree'):\n",
    "    os.makedirs('decision_tree')\n",
    "\n",
    "# Graph\n",
    "plt.plot(list(search_gini.cv_results_.get('param_clf__max_depth')), search_gini.cv_results_.get('mean_test_score'), label = 'Gini criterion')\n",
    "plt.plot(list(search_entropy.cv_results_.get('param_clf__max_depth')), search_entropy.cv_results_.get('mean_test_score'), label = 'Entropy criterion')\n",
    "\n",
    "plt.xlabel(\"Max Tree Depth\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.title(\"Decision Tree: accuracy over max depth (grid search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"decision_tree/decision_tree_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(search_gini.cv_results_.get('param_clf__max_depth')), search_gini.cv_results_.get('mean_fit_time'), label = 'Gini criterion')\n",
    "plt.plot(list(search_entropy.cv_results_.get('param_clf__max_depth')), search_entropy.cv_results_.get('mean_fit_time'), label = 'Entropy criterion')\n",
    "\n",
    "plt.xlabel(\"Max Tree Depth\")\n",
    "plt.ylabel(\"Mean Fit Time (seconds)\")\n",
    "plt.title(\"Decision Tree: time over max depth (grid search)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"decision_tree/decision_tree_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
